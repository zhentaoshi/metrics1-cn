
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>\setcounter{chapter}{5} Asymptotic Properties of Least Squares &#8212; 计量经济学讲义</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">计量经济学讲义</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   前言
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lecture1-CN.html">
   1. 概率论
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2-CN.html">
   2. 投影
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3-CN.html">
   3. 最小二乘法：线性代数观点
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture4-CN.html">
   4. 最小二乘法: 有限样本理论
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5-CN.html">
   5. 基本渐近理论
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture6-CN.html">
   6. 最小二乘法的渐近性质
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture8-CN.html">
   7. 假设检验
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/lecture6.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/zhentaoshi/metrics1-cn"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/zhentaoshi/metrics1-cn/issues/new?title=Issue%20on%20page%20%2Flecture6.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#consistency">
   Consistency
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#asymptotic-distribution">
   Asymptotic Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#asymptotic-inference">
   Asymptotic Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>\setcounter{chapter}{5}
Asymptotic Properties of Least Squares</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#consistency">
   Consistency
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#asymptotic-distribution">
   Asymptotic Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#asymptotic-inference">
   Asymptotic Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="setcounter-chapter-5-asymptotic-properties-of-least-squares">
<h1>\setcounter{chapter}{5}
Asymptotic Properties of Least Squares<a class="headerlink" href="#setcounter-chapter-5-asymptotic-properties-of-least-squares" title="Permalink to this headline">¶</a></h1>
<p>We have learned some basic asymptotic theory in the previous chapter. We
apply these results to study asymptotic properties of the OLS estimator
<span class="math notranslate nohighlight">\(\widehat{\beta}=\left(X'X\right)^{-1}X'Y\)</span>, which is of key interest in
our course. We will show (i) <span class="math notranslate nohighlight">\(\widehat{\beta}\)</span> is a consistent estimator
of the linear projection coefficient <span class="math notranslate nohighlight">\(\beta\)</span>; (ii) <span class="math notranslate nohighlight">\(\widehat{\beta}\)</span> is
asymptotically normal; (iii) the asymptotic normality allows asymptotic
inference of <span class="math notranslate nohighlight">\(\beta\)</span>; (iv) under what condition the variance components
in the test statistic can be consistently estimated so that the testing
procedure is make feasible.</p>
<div class="section" id="consistency">
<h2>Consistency<a class="headerlink" href="#consistency" title="Permalink to this headline">¶</a></h2>
<p><em>Consistency</em> is the most basic requirement for estimators in large
sample. Intuitively, it says that when the sample size is arbitrarily
large, a desirable estimator should be arbitrarily close (in the sense
of convergence in probability) to the population quantity of interest.
Otherwise, if an estimator still deviates from the object of interest
under infinite sample size, it is hard to persuade other researchers to
use such an estimator unless compelling justification is provided.</p>
<p>For a generic estimator <span class="math notranslate nohighlight">\(\widehat{\theta}\)</span>, we say <span class="math notranslate nohighlight">\(\widehat{\theta}\)</span> is
<em>consistent</em> for <span class="math notranslate nohighlight">\(\theta\)</span> if <span class="math notranslate nohighlight">\(\widehat{\theta}\stackrel{p}{\to}\theta\)</span>,
where <span class="math notranslate nohighlight">\(\theta\)</span> is some non-random object.</p>
<p>In OLS, we say <span class="math notranslate nohighlight">\(\widehat{\beta}\)</span> is <em>consistent</em> if
<span class="math notranslate nohighlight">\(\widehat{\beta}\stackrel{p}{\to}\beta\)</span> as <span class="math notranslate nohighlight">\(n\to\infty\)</span>, where <span class="math notranslate nohighlight">\(\beta\)</span>
is the linear projection coefficient of the population model
<span class="math notranslate nohighlight">\(y_{i}=x_{i}'\beta+e_{i}\)</span> with <span class="math notranslate nohighlight">\(E\left[x_{i}e_{i}\right]=0\)</span>. To verify
consistency, we write
$<span class="math notranslate nohighlight">\(\widehat{\beta}-\beta=\left(X'X\right)^{-1}X'e=\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\right)^{-1}\frac{1}{n}\sum_{i=1}^{n}x_{i}e_{i}.\label{eq:ols_d}\)</span>$</p>
<p>For simplicity, in this chapter we discuss the iid setting only. The
first term, by LLN,
$<span class="math notranslate nohighlight">\(\widehat{Q}:=\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\stackrel{p}{\to}Q:=E\left[x_{i}x_{i}'\right].\)</span><span class="math notranslate nohighlight">\(
Here \)</span>\widehat{Q}<span class="math notranslate nohighlight">\( is the sample mean of \)</span>x_{i}x_{i}’<span class="math notranslate nohighlight">\( and \)</span>Q<span class="math notranslate nohighlight">\( is the
population mean of \)</span>x_{i}x_{i}’<span class="math notranslate nohighlight">\(. The second term, again by LLN,
\)</span><span class="math notranslate nohighlight">\(\frac{1}{n}\sum_{i=1}^{n}x_{i}e_{i}\stackrel{p}{\to}0.\)</span><span class="math notranslate nohighlight">\( The
continuous mapping theorem immediately implies
\)</span><span class="math notranslate nohighlight">\(\widehat{\beta}-\beta\stackrel{p}{\to}Q^{-1}\times0=0.\)</span><span class="math notranslate nohighlight">\( The OLS
estimator \)</span>\widehat{\beta}<span class="math notranslate nohighlight">\( is a consistent estimator of \)</span>\beta$.</p>
<p>No matter whether <span class="math notranslate nohighlight">\(\left(y_{i},x_{i}\right)_{i=1}^{n}\)</span> is an iid, or
inid, or dependent sample, consistency holds as long as the convergence
in probability holds for the above two expressions and <span class="math notranslate nohighlight">\(Q\)</span> is an
invertible matrix.</p>
</div>
<div class="section" id="asymptotic-distribution">
<h2>Asymptotic Distribution<a class="headerlink" href="#asymptotic-distribution" title="Permalink to this headline">¶</a></h2>
<p>In finite sample, <span class="math notranslate nohighlight">\(\widehat{\beta}\)</span> is a random variable. We have shown
the distribution of <span class="math notranslate nohighlight">\(\widehat{\beta}\)</span> under normality before. Without
the restrictive normality assumption, how can we characterize the
randomness of the OLS estimator?</p>
<p>We know from the previous section that
<span class="math notranslate nohighlight">\(\hat{\beta}-\beta\stackrel{p}{\to}0\)</span> degenerates to a constant. To
study its distribution, we must scale it up by a proper multiplier so
that in the limit it neither degenerates nor explodes. The suitable
scaling factor is <span class="math notranslate nohighlight">\(\sqrt{n}\)</span>, as in a CLT.
$<span class="math notranslate nohighlight">\(\sqrt{n}\left(\widehat{\beta}-\beta\right)=\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}x_{i}'\right)^{-1}\frac{1}{\sqrt{n}}\sum_{i=1}^{n}x_{i}e_{i}.\)</span><span class="math notranslate nohighlight">\(
Since \)</span>E\left[x_{i}e_{i}\right]=0<span class="math notranslate nohighlight">\(, we apply a CLT to obtain
\)</span><span class="math notranslate nohighlight">\(\frac{1}{\sqrt{n}}\sum_{i=1}^{n}x_{i}e_{i}\stackrel{d}{\to}N\left(0,\Sigma\right)\)</span><span class="math notranslate nohighlight">\(
where \)</span>\Sigma=E\left[x_{i}x_{i}’e_{i}^{2}\right]<span class="math notranslate nohighlight">\(. By the continuous
mapping theorem,
\)</span><span class="math notranslate nohighlight">\(\sqrt{n}\left(\widehat{\beta}-\beta\right)\stackrel{d}{\to}Q^{-1}\times N\left(0,\Sigma\right)\sim N\left(0,\Omega\right)\label{eq:asym_norm}\)</span><span class="math notranslate nohighlight">\(
where \)</span>\Omega=Q^{-1}\Sigma Q^{-1}$ is called the <em>asymptotic variance</em>.
This result is the <em>asymptotic normality</em> of the OLS estimator.</p>
<p>The asymptotic variance <span class="math notranslate nohighlight">\(\Omega=Q^{-1}\Sigma Q^{-1}\)</span> is called of the
<em>sandwich form</em>. It can be simplified under conditional homoskedasticity
<span class="math notranslate nohighlight">\(E\left[e_{i}^{2}|x_{i}\right]=\sigma^{2}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>, which gives
$<span class="math notranslate nohighlight">\(\Sigma=E\left[x_{i}x_{i}'e_{i}^{2}\right]=E\left[x_{i}x_{i}'E\left[e_{i}^{2}|X\right]\right]=\sigma^{2}E\left[x_{i}x_{i}'\right]=\sigma^{2}Q.\)</span><span class="math notranslate nohighlight">\(
In this case, \)</span>\Omega=Q^{-1}\Sigma Q^{-1}=\sigma^{2}Q^{-1}<span class="math notranslate nohighlight">\(, and thus
\)</span><span class="math notranslate nohighlight">\(\sqrt{n}\left(\widehat{\beta}-\beta\right)\stackrel{d}{\to}N\left(0,\sigma^{2}Q^{-1}\right).\label{eq:asym_norm_homo}\)</span>$</p>
<p>If we are interested in the <span class="math notranslate nohighlight">\(k\)</span>-th parameter <span class="math notranslate nohighlight">\(\beta_{k}\)</span>, then the joint
distribution in
(<a class="reference external" href="#eq:asym_norm">[eq:asym_norm]</a>{reference-type=”eqref”
reference=”eq:asym_norm”}) implies $<span class="math notranslate nohighlight">\(\begin{aligned}
\sqrt{n}\left(\widehat{\beta}_{k}-\beta_{k}\right) &amp; =\sqrt{n}\eta_{k}'\left(\widehat{\beta}-\beta\right)\nonumber \\
 &amp; \stackrel{d}{\to}N\left(0,\sigma^{2}\eta_{k}'Q^{-1}\eta_{k}\right)\sim N\left(0,\sigma^{2}[Q^{-1}]_{kk}\right),\label{eq:asym_norm_homok}\end{aligned}\)</span><span class="math notranslate nohighlight">\(
where \)</span>\eta_{k}=\left(0,\ldots,0,1,0\ldots,0\right)’<span class="math notranslate nohighlight">\( is the selector of
the \)</span>k$-th element.</p>
<p>If <span class="math notranslate nohighlight">\(\Omega^{-1/2}\)</span> is multiplied on both sides of
<a class="reference external" href="#eq:asym_norm">[eq:asym_norm]</a>{reference-type=”eqref”
reference=”eq:asym_norm”}, we have
$<span class="math notranslate nohighlight">\(\Omega^{-1/2}\sqrt{n}\left(\widehat{\beta}-\beta\right)\stackrel{d}{\to}N\left(0,I_{K}\right).\label{eq:asym_norm-pivot}\)</span><span class="math notranslate nohighlight">\(
We say the asymptotic distribution in
[\[eq:asym\_norm-pivot\]](#eq:asym_norm-pivot){reference-type=&quot;eqref&quot;
reference=&quot;eq:asym_norm-pivot&quot;}, \)</span>N\left(0,I_{K}\right)<span class="math notranslate nohighlight">\(, is *pivotal*
because it does not involve any unknown parameter. In contrast, the
asymptotic distribution in
[\[eq:asym\_norm\]](#eq:asym_norm){reference-type=&quot;eqref&quot;
reference=&quot;eq:asym_norm&quot;} is not pivotal because \)</span>\Omega<span class="math notranslate nohighlight">\( is unknown in
\)</span>N\left(0,\Omega\right)<span class="math notranslate nohighlight">\(. If we are interested in the \)</span>k<span class="math notranslate nohighlight">\(-th parameter
\)</span>\beta_{k}<span class="math notranslate nohighlight">\(, we can write
[\[eq:asym\_norm-pivot\]](#eq:asym_norm-pivot){reference-type=&quot;eqref&quot;
reference=&quot;eq:asym_norm-pivot&quot;} into the pivotal form as
\)</span><span class="math notranslate nohighlight">\(\frac{\sqrt{n}\left(\widehat{\beta}_{k}-\beta_{k}\right)}{\sqrt{\sigma^{2}[Q^{-1}]_{kk}}}\stackrel{d}{\to}N\left(0,1\right).\label{eq:asym_norm_homok_pivot}\)</span>$</p>
</div>
<div class="section" id="asymptotic-inference">
<h2>Asymptotic Inference<a class="headerlink" href="#asymptotic-inference" title="Permalink to this headline">¶</a></h2>
<p>Up to now we have derived the asymptotic distribution of
<span class="math notranslate nohighlight">\(\widehat{\beta}\)</span>. However,
<a class="reference external" href="#eq:asym_norm">[eq:asym_norm]</a>{reference-type=”eqref”
reference=”eq:asym_norm”} or
<a class="reference external" href="#eq:asym_norm-pivot">[eq:asym_norm-pivot]</a>{reference-type=”eqref”
reference=”eq:asym_norm-pivot”} will be useful for statistical inference
only if <span class="math notranslate nohighlight">\(\Omega\)</span> is known. In reality <span class="math notranslate nohighlight">\(\Omega\)</span> is mostly unknown, and
therefore we will need to estimate it to make statistical inference
feasible. Suppose <span class="math notranslate nohighlight">\(\tilde{\Omega}\)</span> is any consistent estimator for
<span class="math notranslate nohighlight">\(\Omega\)</span> in that <span class="math notranslate nohighlight">\(\tilde{\Omega}\stackrel{p}{\to}\Omega\)</span>. When we
replace <span class="math notranslate nohighlight">\(\Omega\)</span> in
<a class="reference external" href="#eq:asym_norm-pivot">[eq:asym_norm-pivot]</a>{reference-type=”eqref”
reference=”eq:asym_norm-pivot”} with <span class="math notranslate nohighlight">\(\tilde{\Omega}\)</span>, we have
$<span class="math notranslate nohighlight">\(\begin{aligned}
\tilde{\Omega}^{-1/2}\sqrt{n}\left(\widehat{\beta}-\beta\right) &amp; =\tilde{\Omega}^{-1/2}\Omega^{1/2}\times\Omega^{-1/2}\sqrt{n}\left(\widehat{\beta}-\beta\right).\end{aligned}\)</span><span class="math notranslate nohighlight">\(
Because \)</span>\Omega<span class="math notranslate nohighlight">\( is positive definite, we have the first factor
\)</span>\tilde{\Omega}^{-1/2}\Omega^{1/2}\stackrel{p}{\to}I_{K}<span class="math notranslate nohighlight">\( by the
continuous mapping theorem. The second factor is asymptotic normal by
[\[eq:asym\_norm-pivot\]](#eq:asym_norm-pivot){reference-type=&quot;eqref&quot;
reference=&quot;eq:asym_norm-pivot&quot;}. Thus Slutsky's theorem implies
\)</span><span class="math notranslate nohighlight">\(\tilde{\Omega}^{-1/2}\sqrt{n}\left(\widehat{\beta}-\beta\right)\stackrel{d}{\to}N\left(0,I_{K}\right)\label{eq:asym_norm_feasible}\)</span>$
and
<a class="reference external" href="#eq:asym_norm_feasible">[eq:asym_norm_feasible]</a>{reference-type=”eqref”
reference=”eq:asym_norm_feasible”} is a feasible statistic for
asymptotic inference.</p>
<p>The next question is how to consistently estimate
<span class="math notranslate nohighlight">\(\Omega=Q^{-1}\Sigma Q^{-1}\)</span>, or equivalent how to come up with an
<span class="math notranslate nohighlight">\(\tilde{\Omega}\)</span>. We have had <span class="math notranslate nohighlight">\(\widehat{Q}\stackrel{p}{\to}Q\)</span>. If we
have a consistent estimator <span class="math notranslate nohighlight">\(\tilde{\Sigma}\)</span> for <span class="math notranslate nohighlight">\(\Sigma\)</span>, then we can
plug in these consistent estimators to form
<span class="math notranslate nohighlight">\(\tilde{\Omega}=\widehat{Q}^{-1}\tilde{\Sigma}\widehat{Q}^{-1}\)</span>. The
tricky question is how to consistently estimate
<span class="math notranslate nohighlight">\(\Sigma=E\left[x_{i}x_{i}'e_{i}^{2}\right]\)</span>. We cannot use the sample
mean of <span class="math notranslate nohighlight">\(x_{i}x_{i}'e_{i}^{2}\)</span> to estimate <span class="math notranslate nohighlight">\(\Sigma\)</span> because <span class="math notranslate nohighlight">\(e_{i}\)</span> is
unobservable. Under homoskedasticity
<span class="math notranslate nohighlight">\(\Omega=Q^{-1}\Sigma Q^{-1}=\sigma^{2}Q^{-1}\)</span>, and similarly we cannot
use the sample mean of <span class="math notranslate nohighlight">\(e_{i}^{2}\)</span> to estimate <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>.</p>
<p>Heteroskedasticity is ubiquitous in econometrics. A regression example
that naturally generates conditional heteroskedasticity is the <em>linear
probability model</em> <span class="math notranslate nohighlight">\(y_{i}=x_{i}'\beta+e_{i}\)</span>, where
<span class="math notranslate nohighlight">\(y_{i}\in\left\{ 0,1\right\}\)</span> is a binary dependent variable. Assume CEF
as <span class="math notranslate nohighlight">\(E\left[y_{i}|x_{i}\right]=x_{i}'\beta\)</span>, so we can use OLS to
consistently estimate <span class="math notranslate nohighlight">\(\beta\)</span>. The conditional variance
$<span class="math notranslate nohighlight">\(\mathrm{var}\left[e_{i}|x_{i}\right]=\mathrm{var}\left[y_{i}|x_{i}\right]=E\left[y_{i}|x_{i}\right]\left(1-E\left[y_{i}|x_{i}\right]\right)=x_{i}'\beta\left(1-x_{i}'\beta\right)\)</span><span class="math notranslate nohighlight">\(
explicitly depends on \)</span>x_{i}<span class="math notranslate nohighlight">\(. In other words, the conditional variance
varies with \)</span>x_{i}$.</p>
<p>Naturally, one may attempt to use the OLS residual
<span class="math notranslate nohighlight">\(\widehat{e}_{i}=\widehat{y}_{i}-x_{i}'\widehat{\beta}\)</span> to replace the
regression error <span class="math notranslate nohighlight">\(e_{i}\)</span>, so that we would have the plug-in estimators
<span class="math notranslate nohighlight">\(\widehat{\Omega}=\widehat{\sigma}^{2}\widehat{Q}^{-1}\)</span> for
homoskedasticity, where
<span class="math notranslate nohighlight">\(\widehat{\sigma}^{2}=\widehat{e}'\widehat{e}/\left(n-K\right)\)</span> or
<span class="math notranslate nohighlight">\(\widehat{\sigma}^{2}=\widehat{e}'\widehat{e}/n\)</span>, and
<span class="math notranslate nohighlight">\(\widehat{\Omega}=\widehat{Q}^{-1}\widehat{\Sigma}\widehat{Q}^{-1}\)</span> for
heteroskedasticity, where
<span class="math notranslate nohighlight">\(\widehat{\Sigma}=n^{-1}\sum_{i}x_{i}x_{i}'\widehat{e}_{i}^{2}\)</span>.</p>
<p>\medskip{}
If we choose
<span class="math notranslate nohighlight">\(\widehat{\sigma}^{2}=\widehat{e}'\widehat{e}/\left(n-K\right)\)</span> and
replace <span class="math notranslate nohighlight">\(\sigma^{2}\)</span> in
<a class="reference external" href="#eq:asym_norm_homok_pivot">[eq:asym_norm_homok_pivot]</a>{reference-type=”eqref”
reference=”eq:asym_norm_homok_pivot”}, then the resulting statistic
<span class="math notranslate nohighlight">\(T_{k}=\frac{\sqrt{n}\left(\widehat{\beta}_{k}-\beta_{k}\right)}{\sqrt{\widehat{\sigma}^{2}[\widehat{Q}^{-1}]_{kk}}}\)</span>
is exactly the <span class="math notranslate nohighlight">\(t\)</span>-statistic in the finite sample analysis. Recall that
under the classical normal-error assumption, the <span class="math notranslate nohighlight">\(t\)</span>-statistics follows
exact finite sample <span class="math notranslate nohighlight">\(t\)</span>-distribution with degrees of freedom <span class="math notranslate nohighlight">\(n-K\)</span>. In
asymptotic analysis, we allow <span class="math notranslate nohighlight">\(e_{i}\)</span> to be any distribution if
<span class="math notranslate nohighlight">\(E\left[e_{i}^{2}|x_{i}\right]&lt;\infty\)</span> (We impose this assumption for
simplicity. It can be further relaxed in inid cases.) The asymptotic
normality allows us to conduct asymptotic statistical inference. For the
same <span class="math notranslate nohighlight">\(t\)</span>-statistic, we must draw the critical values from the normal
distribution, because
$<span class="math notranslate nohighlight">\(T_{k}=\frac{\sqrt{\sigma^{2}[Q^{-1}]_{kk}}}{\sqrt{\widehat{\sigma}^{2}[\widehat{Q}^{-1}]_{kk}}}\cdot\frac{\sqrt{n}\left(\widehat{\beta}_{k}-\beta_{k}\right)}{\sqrt{\sigma^{2}[Q^{-1}]_{kk}}}\stackrel{d}{\to}1\times N\left(0,1\right)\sim N\left(0,1\right)\)</span><span class="math notranslate nohighlight">\(
by Slutsky's theorem if
\)</span>\widehat{\sigma}^{2}\stackrel{p}{\to}\sigma^{2}$.</p>
<p>\medskip{}
The next section will give sufficient conditions for
<span class="math notranslate nohighlight">\(\widehat{\sigma}^{2}\stackrel{p}{\to}\sigma^{2}\)</span> and
<span class="math notranslate nohighlight">\(\widehat{\Sigma}\stackrel{p}{\to}\Sigma\)</span>.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>One of the most important techniques in asymptotic theory is
manipulating inequalities. These derivations of the variances look
complicated at first glance, but is often encountered in proofs of
theoretical results. After many years of torment, you will be accustomed
to these routine calculations.</p>
<p><strong>Historical notes</strong>: &#64;white1980heteroskedasticity drew attention of
economic contexts that violate the classical statistical assumptions in
linear regressions. It seeded econometricians’ care, or obsession, in
variance estimation for statistical inference. The following decades has
witnessed a plethora of proposals of variance estimation that deal with
various deviation from the classical assumptions.</p>
<p><strong>Further reading</strong>: In this chapter all vectors are of finite
dimensional. Some results can be extended to allow infinite <span class="math notranslate nohighlight">\(K\)</span> when
<span class="math notranslate nohighlight">\(K\to\infty\)</span> at a much slower speed than <span class="math notranslate nohighlight">\(n\)</span>. Such asymptotic
development will require multiple indices, and it goes beyond the
simplest case of <span class="math notranslate nohighlight">\(n\to\infty\)</span> that we learned here. Big data is
accompanied by big model, in which the model itself is indexed by the
sample size and can grow more sophisticated as <span class="math notranslate nohighlight">\(n\)</span> get bigger. In the
proofs of my latest paper &#64;shi2020high, You will find loads of
inequality operations of similar flavor to this chapter.</p>
</div>
<div class="section" id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<p>We introduce the “big Op and small op” notation. They are the stochastic
counterparts of the “big O and small o” notation in deterministic cases.</p>
<ul class="simple">
<li><p>Small op: <span class="math notranslate nohighlight">\(x_{n}=o_{p}\left(r_{n}\right)\)</span> if
<span class="math notranslate nohighlight">\(x_{n}/r_{n}\stackrel{p}{\to}0\)</span>.</p></li>
<li><p>Big Op: <span class="math notranslate nohighlight">\(x_{n}=O_{p}\left(r_{n}\right)\)</span> if for any <span class="math notranslate nohighlight">\(\varepsilon&gt;0\)</span>,
there exists a <span class="math notranslate nohighlight">\(c&gt;0\)</span> such that
<span class="math notranslate nohighlight">\(P\left(\left|x_{n}\right|/r_{n}&gt;c\right)&lt;\varepsilon\)</span>.</p></li>
</ul>
<p>Some operations:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(o_{p}\left(1\right)+o_{p}\left(1\right)=o_{p}\left(1\right)\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(o_{p}\left(1\right)+O_{p}\left(1\right)=O_{p}\left(1\right)\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(o_{p}\left(1\right)O_{p}\left(1\right)=o_{p}\left(1\right)\)</span>.</p></li>
</ul>
<p>The big Op and small op notation allows us to keep using equalities in
calculation while expressing the stochastic order of random objects.</p>
<p>\bigskip
<code class="docutils literal notranslate"> <span class="pre">Zhentao</span> <span class="pre">Shi.</span> <span class="pre">Oct</span> <span class="pre">21,</span> <span class="pre">2020.</span></code></p>
<p>\bibliographystyle{chicagoa}</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 史震涛 Shi Zhentao<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>