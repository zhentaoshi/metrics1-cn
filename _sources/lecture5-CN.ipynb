{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fbecd8",
   "metadata": {},
   "source": [
    "#  基本渐近理论\n",
    "\n",
    "\n",
    "```{admonition}  赤壁赋\n",
    "寄蜉蝣于天地，渺沧海之一粟。哀吾生之须臾，羡长江之无穷。挟飞仙以遨游，抱明月而长终。\n",
    " ```\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7363164",
   "metadata": {},
   "source": [
    "\n",
    "我们身处的浩瀚宇宙当中, 原子的数目小于 $10^{82}$ 个。这是一个天文数字，然而也是一个有限的数字. 然而, 数学思想并不受制于现实. 渐进理论 (Asymptotic theory) 是一门有关无限的艺术, 它研究统计量在样本量趋于无穷大之时的性质与行为. 它用一系列“近似”的技巧来简化复杂的有限样本问题. 渐近理论是现代计量经济学的基石. 它超越了有限样本理论所涵盖范围, 揭示了在更普遍情况下的统计估计与推断理论. \n",
    "\n",
    "\n",
    "然而现实与理想相悖：我们手中的样本量总是有限的, 而且在大多数情况下, 我们也很难去增加样本量. 渐近理论虽然研究无穷大, 却不能准确回答 \"多大才是大\"这个问题. 因此, 我们必须警惕 *渐近乌托邦 (asymptopia)* 的出现. 在大数据时代, 尽管数据的规模急剧膨胀, 同时我们希望建立复杂的模型来更好地捕捉数据的异质性. 大样本是一个相对的概念, 依赖于模型的复杂性和数据的基本生成过程. \n",
    "\n",
    "一方面，经典的参数化方法建立在难以验证的参数假设之上. 另一方面，渐进理论以假想的无限序列为前提. 可以说, 二者都偏离了现实. 哪种方法更有建设性? 我们只能根据具体情况来判断. 渐进理论的优点在于它数学上的普遍性与易操作性. 正因如此, 渐进理论摘得我们这个时代数理统计学的桂冠. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088387d",
   "metadata": {},
   "source": [
    "## 随机变量的收敛模式\n",
    "\n",
    "\n",
    "首先回顾一下什么是非随机序列的收敛. \n",
    "\n",
    "```{prf:definition} 非随机序列的收敛\n",
    ":label: con_of_dv\n",
    "\n",
    "假设 $z_{1}, z_{2}, \\ldots$ 是一个非随机的无限序列. 如果对于任意 $\\varepsilon>0$, 存在 $N\\left(\\varepsilon\\right)$ 使得：对于所有 $n>N\\left(\\varepsilon\\right)$, 都有\n",
    "$\\left|z_{n}-z\\right|<\\varepsilon$, 那么称 $\\{z_n\\}$ 是收敛序列. \n",
    "\n",
    "我们将 $z$ 称作 $z_{n}$ 的极限, 并记 $z_{n}\\to z$, 或者 $\\lim_{n\\to\\infty}z_{n}=z$. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a667c6",
   "metadata": {},
   "source": [
    "\n",
    "然而我们感兴趣的不是确定性序列, 而是随机变量序列. 何谓随机变量的收敛? 我们在此定义几种随机变量的收敛模式. 设 $\\left(z_{n}\\right)$ 是一个随机变量序列, $z$ 是随机变量或非随机常数.\n",
    "\n",
    "```{prf:definition} 依概率收敛 (Convergence in probability)\n",
    ":label: con_in_prob\n",
    "\n",
    " 如果对于任意 $\\varepsilon>0$, 当 $n\\to\\infty$ 时, 都有 $P\\left\\{ \\omega:\\left|z_{n}\\left(\\omega\\right)-z\\right|<\\varepsilon\\right\\} \\to 1$ (或者等价地, $P\\left\\{ \\omega:\\left|z_{n}\\left(\\omega\\right)-z\\right|\\geq\\varepsilon\\right\\} \\to0$) , 则称随机变量序列 $\\left(z_{n}\\right)$ 依概率收敛到 $z$, 记作 $z_{n}\\stackrel{p}{\\to}z$. \n",
    "```\n",
    "\n",
    "```{prf:definition} 均方收敛 (Convergence in mean square)\n",
    ":label: con_in_ms\n",
    "\n",
    "如果当 $n\\to\\infty$ 时, $E\\left[\\left(z_{n}-z\\right)^{2}\\right]\\to0$， 则称随机变量序列$\\left(z_{n}\\right)$ 均方收敛到 $z$, 记作 $z_{n}\\stackrel{m. s. }{\\to}z$. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184018a",
   "metadata": {},
   "source": [
    "在 {prf:ref}`con_in_prob` 与 {prf:ref}`con_in_ms` 中, $P\\left\\{ \\omega:\\left|z_{n}\\left(\\omega\\right)-z\\right|>\\varepsilon\\right\\}$ 与 $E\\left[\\left(z_{n}-z\\right)^{2}\\right]$ 都是非随机的. 它们依非随机序列的收敛方式 ({prf:ref}`con_of_dv`) 趋近于0. \n",
    "\n",
    "注意, 均方收敛的假设比依概率收敛的假设更强. 也就是说, 可以从 $z_{n}\\stackrel{m. s. }{\\to}z$ 推导出 $z_{n}\\stackrel{p}{\\to}z$, 但反过来不成立. 下面是一个例子. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c338a6",
   "metadata": {},
   "source": [
    "\n",
    "````{prf:example}\n",
    ":label: in_p_in_ms\n",
    "\n",
    "$(z_{n})$ 是一个随机变量序列. $z_{n}=\\sqrt{n}$ 的概率为 $1/n$, $z_{n}=0$ 的概率为 $1-1/n$. 那么 $z_{n}\\stackrel{p}{\\to}0$, 但 $z_{n}\\stackrel{m. s. }{\\nrightarrow}0$. \n",
    "\n",
    "```{prf:proof}\n",
    "注意到, 对于任意 $\\varepsilon>0$, $P\\left(\\omega:\\left|z_{n}\\left(\\omega\\right)-0\\right|<\\varepsilon\\right)=P\\left(\\omega:z_{n}\\left(\\omega\\right)=0\\right)=1-1/n\\rightarrow1$, 因此 $z_{n}\\stackrel{p}{\\to}0$. 同时, $E\\left[\\left(z_{n}-0\\right)^{2}\\right]=n\\cdot1/n+0\\cdot(1-1/n)=1\\nrightarrow0$, 所以 $z_{n}\\stackrel{m. s. }{\\nrightarrow}0$. \n",
    "```\n",
    "````\n",
    "\n",
    "```{prf:remark}\n",
    ":label: remark1\n",
    "\n",
    "{prf:ref}`in_p_in_ms` 揭示了两种收敛方式的不同. 依概率收敛并不考虑小概率事件是后果, 而均方收敛涉考虑的则是整个概率空间上的平均值. 如果某个随机变量可以取一个巨大的值, 即使这是小概率事件, 它也可能会影响均方收敛, 却并不会破坏依概率收敛. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53ebf1",
   "metadata": {},
   "source": [
    "依概率收敛与均方收敛都事关一个随机变量收敛至另一个随机变量或者常数. 也就是说, 当 $n\\to\\infty$ 时, $z_{n}-z$ 的分布聚集在 0 左右. 但是, *依分布收敛 (convergence in distribution*) 关心的却是 *累积分布函数CDF* 的收敛方式, 并非随机变量的收敛方式. \n",
    "\n",
    "```{prf:definition} 依分布收敛 Convergence in distribution\n",
    ":label: con_in_dist\n",
    "\n",
    "设 $F_{z_{n}}\\left(\\cdot\\right)$ 随机变量序列 $z_{n}$ 的累积分布函数, $F_{z}\\left(\\cdot\\right)$ 的累计分布函数. 如果对于 $F_{z}\\left(\\cdot\\right)$ 的任意连续点 $a\\in\\mathbb{R}$, 当 $n\\to\\infty$ 时, 都有 $F_{z_{n}}\\left(a\\right)\\to F_{z}\\left(a\\right)$, 那么称随机变量序列$\\left(z_{n}\\right)$ 依分布收敛到随机变量 $z$, 记作 $z_{n}\\stackrel{d}{\\to}z$. \n",
    "```\n",
    "\n",
    "依分布收敛是一种弱收敛性质. 如果 $z_{n}\\stackrel{p}{\\to}z$, 则 $z_{n}\\stackrel{d}{\\to}z$. 反之不一定成立, 除非 $z$ 是一个(非随机)常数 (常数 $z$ 可以被视作一个退化的随机变量, 其累积分布函数可写作 $F_{z}\\left(\\cdot\\right)=1\\left\\{ \\cdot\\geq z\\right\\}$) . \n",
    "\n",
    "```{prf:example}\n",
    ":label: in_p_in_dist\n",
    "\n",
    "假设 $x\\sim N\\left(0, 1\\right)$. \n",
    "* 若 $z_{n}=x+1/n$, 则 $z_{n}\\stackrel{p}{\\to}x$, 且 $z_{n}\\stackrel{d}{\\to}x$. \n",
    "* 若 $z_{n}=-x+1/n$, 或 $z_{n}=y+1/n$ (其中 $y\\sim N\\left(0, 1\\right)$ 与 $x$ 独立) , 则 $z_{n}\\stackrel{p}{\\to}x$, 但 $z_{n}\\stackrel{p}{\\nrightarrow}x$. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c309a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "````{prf:example}\n",
    ":label: in_dist\n",
    "\n",
    "$(z_{n})$ 是一个随机变量序列. $z_{n}=\\sqrt{n}$ 的概率为 $1/\\sqrt{n}$, $z_{n}=0$ 的概率为 $1-1/\\sqrt{n}$. 那么 $z_{n}\\stackrel{d}{\\to}z=0$. \n",
    "\n",
    "```{prf:proof}\n",
    "注意到\n",
    "\n",
    "$$\n",
    "F_{z_{n}}\\left(a\\right)=\\begin{cases}\n",
    "0 & a<0\\\\\n",
    "1-1/\\sqrt{n} & 0\\leq a\\leq n\\\\\n",
    "1 & a\\geq n\n",
    "\\end{cases}. \n",
    "$$\n",
    "\n",
    "同时, \n",
    "\n",
    "$$\n",
    "F_{z}\\left(a\\right)=\\begin{cases} 0, & a<0\\\\ 1 & a\\geq0 \\end{cases}. \n",
    "$$\n",
    "\n",
    "易验证, 在定义域 $\\left(-\\infty, 0\\right)\\cup\\left(0, +\\infty\\right)$ 上, $F_{z_{n}}\\left(a\\right)$ 逐点收敛于 $F_{z}\\left(a\\right)$, 其中 $F_{z}\\left(a\\right)$ 是连续函数. \n",
    "\n",
    "```\n",
    "````\n",
    "\n",
    "到目前为止, 我们已经讨论了随机标量的收敛性. 这三种收敛模式可以很容易地推广到随机向量. 具体来说, 可以运用 *Cramer-Wold device*, 通过任意的线性组合, 将随机向量折叠成随机向量. 假设 $\\left(z_{n}\\right)$ 是一个 $K$ 维的随机向量序列, $z$ 是一个$K$ 维向量. 如果对于任意 $\\lambda\\in\\mathbb{R}^{K}$, $\\left\\Vert \\lambda\\right\\Vert _{2}=1$, 都有 $\\lambda'z_{n}\\stackrel{d}{\\to}\\lambda'z$, 那么称随机向量序列$\\left(z_{n}\\right)$ 依分布收敛到 $z$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6198c",
   "metadata": {},
   "source": [
    "## 大数定律\n",
    "\n",
    "(弱) 大数定律 ((weak) law of large numbers) 是一组关于 *样本均值依概率收敛至总体均值* 的定理. \n",
    "\n",
    "大数定律的基本形式是, 当 $n\\to\\infty$ 时, 有\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^{n}(z_{i}-E[z_{i}])\\stackrel{p}{\\to}0. \n",
    "$$ \n",
    "\n",
    "不同版本的大数定律基于不同的假设, 也取决于对应随机变量的不同相依性(dependence). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bbd11",
   "metadata": {},
   "source": [
    "### Chebyshev大数定律\n",
    "\n",
    "\n",
    "我们从最简单的Chebyshev大数定律入手, 来理解大数定律. Chebyshev大数定律利用了*Chebyshev不等式*, 其定义如下. \n",
    "\n",
    "```{prf:theorem} Chebyshev不等式\n",
    ":label: cheb_ineq\n",
    "\n",
    "如果随机变量 $x$ 的二阶矩存在且有限 $E\\left[x^{2}\\right]<\\infty$, 那么对于任意 $\\varepsilon>0$, 都有 \n",
    "\n",
    "$$\n",
    "P\\left\\{ \\left|x\\right|>\\varepsilon\\right\\} \\leq \\frac{E\\left[x^{2}\\right]}{\\varepsilon^{2}}. \n",
    "$$\n",
    "\n",
    "```\n",
    "\n",
    "```{exercise}\n",
    ":label: exercise51\n",
    "\n",
    "证明：若 $r_{2}\\geq r_{1}\\geq1$, 则由 $E\\left[\\left|x\\right|^{r_{2}}\\right]<\\infty$ 可推断出 $E\\left[\\left|x\\right|^{r_{1}}\\right]<\\infty$. (提示：使用 Holder’s 不等式. ) \n",
    "```\n",
    "\n",
    "其实, Chebyshev不等式是 *Markov不等式* 的一种特殊情况. \n",
    "\n",
    "```{prf:theorem} Markov不等式\n",
    ":label: markov_ineq\n",
    "\n",
    "如果随机变量 $x$ 的 $r$ 阶矩 ($r\\ge1$) 存在且有限 $E\\left[\\left|x\\right|^{r}\\right]<\\infty$, 则对于任意 $\\varepsilon>0$, 都有 \n",
    "\n",
    "$$\n",
    "P\\left\\{ \\left|x\\right|>\\varepsilon\\right\\} \\leq \\frac{E\\left[\\left|x\\right|^{r}\\right]}{\\varepsilon^{r}}. \n",
    "$$\n",
    "```\n",
    "\n",
    "Markov不等式的证明十分简单. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fbf7b",
   "metadata": {},
   "source": [
    "\n",
    "```{prf:proof}\n",
    "\n",
    "注意到\n",
    "\n",
    "$$\n",
    "\\begin{aligned}E\\left[\\left|x\\right|^{r}\\right] & =\\int_{\\left|x\\right|>\\varepsilon}\\left|x\\right|^{r}dF_{X}+\\int_{\\left|x\\right|\\leq\\varepsilon}\\left|x\\right|^{r}dF_{X}\\\\\n",
    " & \\geq\\int_{\\left|x\\right|>\\varepsilon}\\left|x\\right|^{r}dF_{X}\\\\\n",
    " & \\geq\\varepsilon^{r}\\int_{\\left|x\\right|>\\varepsilon}dF_{X}=\\varepsilon^{r}P\\left\\{ \\left|x\\right|>\\varepsilon\\right\\} , \n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "重新排列此不等式, 即可得到 Markov 不等式. \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "接下来我们推导 Chebyshev 大数定律. \n",
    "\n",
    "假设 *部分和 (partial sum)* $S_{n}=\\sum_{i=1}^{n}x_{i}$, 同时记 $\\mu_{i}=E\\left[x_{i}\\right]$, $\\sigma_{i}^{2}=\\mathrm{var}\\left[x_{i}\\right]$. \n",
    "\n",
    "对样本均值 $z_{n}=\\overline{x}-\\bar{\\mu}=n^{-1}\\left(S_{n}-E\\left[S_{n}\\right]\\right)$ 运用 Chebyshev 不等式, 得到\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P\\left\\{ \\left|z_{n}\\right|\\geq\\varepsilon\\right\\}  & =P\\left\\{ n^{-1}\\left|S_{n}-E\\left[S_{n}\\right]\\right|\\geq\\varepsilon\\right\\} \\\\\n",
    " & \\leq E\\left[\\left(n^{-1}\\sum_{i=1}^{n}\\left(x_{i}-\\mu_{i}\\right)\\right)^{2}\\right]/\\varepsilon^{2}\\\\\n",
    " & =\\left(n\\varepsilon\\right)^{-2}\\left\\{ E\\left[\\sum_{i=1}^{n}\\left(x_{i}-\\mu_{i}\\right)^{2}\\right]+\\sum_{i=1}^{n}\\sum_{j\\neq i}E\\left[\\left(x_{i}-\\mu_{i}\\right)\\left(x_{j}-\\mu_{j}\\right)\\right]\\right\\} \\\\\n",
    " & =\\left(n\\varepsilon\\right)^{-2}\\left\\{ \\sum_{i=1}^{n}\\mathrm{var}\\left(x_{i}\\right)+\\sum_{i=1}^{n}\\sum_{j\\neq i}\\mathrm{cov}\\left(x_{i}, x_{j}\\right)\\right\\}. \n",
    " \\end{aligned}\n",
    "$$(eqn:cheb_mean)\n",
    "\n",
    "如果在 $n\\to\\infty$ 时, 右式趋近于0, 那么 $z_{n}$ 依概率收敛至0. 比如, 若 $x_{1}, \\ldots, x_{n}$ 是 iid 变量, $\\mathrm{var}\\left(x_{1}\\right)=\\sigma^{2}$, 那么 {eq}`eqn:cheb_mean` 右式 $\\left(n\\varepsilon\\right)^{-2}\\left(n\\sigma^{2}\\right)=o\\left(n^{-1}\\right)\\to0$. \n",
    "\n",
    "至此, 我们已经得到了 Chebyshev 大数定律. \n",
    "\n",
    "\n",
    "```{prf:theorem} Chebyshev 大数定律\n",
    ":label: cheb_lln\n",
    "\n",
    "如果 $\\left(z_{1}, \\ldots, z_{n}\\right)$ 是独立同分布 (iid) 的随机样本, $E\\left[z_{1}\\right]=\\mu$, $\\sigma^{2}=\\mathrm{var}\\left[z_{1}\\right]<\\infty$ 存在, 则\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^{n}z_{i}\\stackrel{p}{\\to}\\mu. \n",
    "$$\n",
    "```\n",
    "\n",
    "事实上, 依概率收敛的大数定律可以去除独立同分布 (iid) 的假设; 样本中的随机变量可以不是同分布的, 也不必相互独立. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43131792",
   "metadata": {},
   "source": [
    "\n",
    "```{exercise}\n",
    ":label: exercise52\n",
    "\n",
    "考虑一组相互独立 (不一定同分布) 的随机样本 $\\left(x_{1}, \\ldots, x_{n}\\right)$ 使得 $E\\left[x_{i}\\right]=0$, $\\mathrm{var}\\left[x_{i}\\right]=\\sqrt{n}c$, $c>0$是常数. 利用 Chebyshev 不等式, 证明 $n^{-1}\\sum_{i=1}^{n}x_{i}\\stackrel{p}{\\to}0$. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a21f792",
   "metadata": {},
   "source": [
    "\n",
    "```{exercise}\n",
    ":label: exercise52\n",
    "\n",
    "考虑一组时间序列的移动平均 (MA) 模型 $x_{i}=\\varepsilon_{i}+\\theta\\varepsilon_{i-1}$, $i=1, \\ldots, n$. 其中, $\\left|\\theta\\right|<1$, $E\\left[\\varepsilon_{i}\\right]=0$, $\\mathrm{var}\\left[\\varepsilon_{i}\\right]=\\sigma^{2}$, 并且 $\\left(\\varepsilon_{i}\\right)_{i=0}^{n}$ 是独立同分布的白噪声序列. 利用 Chebyshev 不等式, 证明 $n^{-1}\\sum_{i=1}^{n}x_{i}\\stackrel{p}{\\to}0$. \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc1d81",
   "metadata": {},
   "source": [
    "### Kolmogorov大数定律\n",
    "\n",
    "大数定律的另一个常见版本是*Kolmogorov大数定律*. 要导出 Kolmogorov大数定律, 需要更高阶的概率论知识, 因此我们只在此给出结果, 略去证明. \n",
    "\n",
    "\n",
    "```{prf:theorem} Kolmogorov LLN\n",
    ":label: kolm_lln\n",
    "\n",
    "如果 $\\left(z_{1}, \\ldots, z_{n}\\right)$ 是独立同分布 (iid) 的随机样本, $E\\left[z_{1}\\right]=\\mu$ 存在, 那么\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^{n}z_{i}\\stackrel{p}{\\to}\\mu. \n",
    "$$\n",
    " ```\n",
    "\n",
    "与 Chebyshev大数定律相比, Kolmogorov大数定律只要求总体均值是存在的, 并不对更高阶的矩作要求. 独立同分布的假设对于Kolmogorov大数定律来说已然足够. \n",
    "\n",
    "\n",
    "````{prf:example}\n",
    ":label: in_dist\n",
    "\n",
    "考虑三种分布, 标准正态分布 $N\\left(0, 1\\right)$, $t$-分布 $t\\left(2\\right)$ (均值为0, 方差无限大) , 柯西分布 (所有的矩都不存在) . 在不同样本容量 $n=2^{1}, 2^{2}, \\ldots, 2^{20}$ 的假设下, 绘制出样本均值的轨迹图. 我们发现, $N\\left(0, 1\\right)$ 与 $t\\left(2\\right)$ 的样本均值收敛, 而柯西分布的样本均值并不收敛. \n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62f120",
   "metadata": {},
   "source": [
    "[need translation]\n",
    "\n",
    "This script demonstrates the law of large numbers (LLN) along with the underlying assumptions.\n",
    "\n",
    "Write a function to generate the sample mean given the sample size $n$ and the distribution.\n",
    "We allow three distributions, namely, $N(0,1)$, $t(2)$ and Cauchy.\n",
    "\n",
    "The sample size is chosen as $2^x$, where $x=1:20$. We have the following observations.\n",
    "\n",
    "* When the distribution is $N(0,1)$, the Chebyshev LLN works. The sample mean converges fast.\n",
    "* When the distribution is $t(2)$, which has zero mean but infinite variance, the Kolmogorov LLN works. The sample mean still converges, though more slowly than the $N(0,1)$ case.\n",
    "* The Cauchy distribution has no moment at any order. The sample mean does not converge no matter how large is the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a5f01",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sample.mean = function( n, distribution ){\n",
    "  # get sample mean for a given distribution\n",
    "  if (distribution == \"normal\"){ y = rnorm( n ) } \n",
    "  else if (distribution == \"t2\") {y = rt(n, 2) }\n",
    "  else if (distribution == \"cauchy\") {y = rcauchy(n) }\n",
    "  return( mean(y) )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db2754",
   "metadata": {},
   "source": [
    "This function plots the sample mean over the path of geometrically increasing sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e5b73",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "LLN.plot = function(distribution){\n",
    "  # draw the sample mean graph\n",
    "  ybar = matrix(0, length(NN), 3 )\n",
    "  for (rr in 1:3){\n",
    "    for ( ii in 1:length(NN)){\n",
    "      n = NN[ii]; ybar[ii, rr] = sample.mean(n, distribution)\n",
    "    }  \n",
    "  }\n",
    "  matplot(ybar, type = \"l\", ylab = \"mean\", xlab = \"\", \n",
    "       lwd = 1, lty = 1, main = distribution)\n",
    "  abline(h = 0, lty = 2)\n",
    "  return(ybar)\n",
    "}\n",
    "# calculation\n",
    "NN = 2^(1:20); set.seed(2020-10-7); par(mfrow = c(3,1))\n",
    "l1 = LLN.plot(\"normal\"); l2 = LLN.plot(\"t2\"); l3 = LLN.plot(\"cauchy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c167f6",
   "metadata": {},
   "source": [
    "\n",
    "## 中心极限定理\n",
    "\n",
    "中心极限定理 (central limit theorem) 是一组关于某随机变量序列 *依分布收敛至某稳定分布* 的定理. 极限分布通常是正态分布. \n",
    "\n",
    "```{prf:theorem} 中心极限定理\n",
    ":label: clt\n",
    "\n",
    "*在适当条件下*, 对于均值为0的随机样本 $\\left(z_{1}, \\ldots, z_{n}\\right)$, 当 $n\\to\\infty$ 时, \n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}z_{i}\\stackrel{d}{\\to}N\\left(0, \\sigma^{2}\\right). \n",
    "$$\n",
    "\n",
    "```\n",
    "\n",
    "不同版本的中心极限定理基于对随机变量的不同假设. 其中, *Lindeberg-Levy 中心极限定理* 最为简单. \n",
    "\n",
    "```{prf:theorem} Lindeberg-Levy CLT\n",
    ":label: ll-clt\n",
    "\n",
    "假设 $\\left(x_{1}, \\ldots, x_{n}\\right)$ 是独立同分布的样本, $E\\left[x_{1}\\right]=0$, $\\mathrm{var}\\left[x_{1}\\right]=\\sigma^{2}<\\infty$, 那么\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}x_{i}\\stackrel{d}{\\to}N\\left(0, \\sigma^{2}\\right). \n",
    "$$\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Lindeberg-Levy 中心极限定理的证明依赖于 *矩母函数 (MGF, moment generating function)*. \n",
    "\n",
    "\n",
    "```{prf:definition} 矩生成函数 MGF\n",
    ":label: mgf\n",
    "随机变量 $x$ 的矩生成函数定义为：\n",
    "\n",
    "$$\n",
    "M_{x}\\left(t\\right)=E\\left[\\exp\\left(xt\\right)\\right], \n",
    "$$\n",
    "\n",
    "前提是这个期望值存在. \n",
    "```\n",
    "\n",
    "\n",
    "与概率密度函数和累积分布函数一样, 矩母函数也可以完全刻画了一个分布. 例如, 正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的矩母函数是 $\\exp\\left(\\mu t+\\frac{1}{2}\\sigma^{2}t^{2}\\right)$. \n",
    "\n",
    "```{prf:proof}\n",
    "如果对于任意正整数 $k$, 都有 $E\\left[\\left|x\\right|^{k}\\right]<\\infty$, 那么\n",
    "\n",
    "$$\n",
    "M_{X}\\left(t\\right)=1+tE\\left[X\\right]+\\frac{t^{2}}{2}E\\left[X^{2}\\right]+\\ldots\\frac{t}{k!}E\\left[X^{k}\\right]+O\\left(t^{k+1}\\right). \n",
    "$$\n",
    "\n",
    "在 {prf:ref}`Lindeberg-Levy CLT <ll-clt>` 的假设下, 对于任意 $i$, 都有\n",
    "\n",
    "$$\n",
    "M_{\\frac{X_{i}}{\\sqrt{n}}}\\left(t\\right)=1+\\frac{t^{2}}{2n}\\sigma^{2}+O\\left(\\frac{t^{3}}{n^{3/2}}\\right). \n",
    "$$\n",
    "\n",
    "根据独立性, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M_{\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}x_{i}}\\left(t\\right) & =\\prod_{i=1}^{n}M_{\\frac{X_{i}}{\\sqrt{n}}}\\left(t\\right)=\\left(1+\\frac{t^{2}}{2n}\\sigma^{2}+O\\left(\\frac{t^{3}}{n^{3/2}}\\right)\\right)^{n}\\\\\n",
    " & \\to\\exp\\left(\\frac{\\sigma^{2}}{2}t^{2}\\right). \n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "右式的极限分布恰为正态分布的 $N\\left(0, \\sigma^{2}\\right)$ 的矩母函数. \n",
    "```\n",
    "\n",
    "```{prf:remark}\n",
    ":label: remark51\n",
    "上述依赖于 MGF 的证明非常易于理解, 但缺点在于, 并非所有分布都有定义良好的矩母函数. 更一般的证明过程是把矩母函数替换为 *特征函数(characteristic function)* $\\varphi_{x}\\left(t\\right)=E\\left[\\exp\\left(\\mathrm{i}xt\\right)\\right]$, 其中 “$\\mathrm{i}$” 是虚数单位. 特征函数是概率测度的 *傅立叶变换* , 它必然存在. 用这种方法来证明中心极限定理, 需要傅立叶变换与逆转换的知识, 我们在这里不做要求. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78522033",
   "metadata": {},
   "source": [
    "\n",
    "我们继续介绍中心极限定理的两种常见形式. \n",
    "\n",
    "\n",
    "```{prf:theorem} Lindeberg-Feller CLT\n",
    ":label: lf-clt\n",
    "\n",
    "假设 $\\left(x_{1}, \\ldots, x_{n}\\right)$ 是相互独立的样本. 如果满足 *Lindeberg condition* (对于任意 $\\varepsilon>0$, \n",
    "    $\\frac{1}{s_{n}^{2}}\\sum_{i=1}^{n}E\\left[x_{i}^{2}\\cdot\\boldsymbol{1}\\left\\{ \\left|x_{i}\\right|\\geq\\varepsilon s_{n}\\right\\} \\right]\\to0$, 其中 $s_{n}=\\sqrt{\\sum_{i=1}^{n}\\sigma_{i}^{2}}$) , 那么\n",
    "    \n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{n}x_{i}}{s_{n}}\\stackrel{d}{\\to}N\\left(0, 1\\right). \n",
    "$$\n",
    "```\n",
    "\n",
    "```{prf:theorem} Lyapunov CLT\n",
    ":label: lya-clt\n",
    "\n",
    "假设 $\\left(x_{1}, \\ldots, x_{n}\\right)$ 是相互独立的样本. 如果 $\\max_{i\\leq n}E\\left[\\left|x_{i}\\right|^{3}\\right]<C<\\infty$, 那么有\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{n}x_{i}}{s_{n}}\\stackrel{d}{\\to}N\\left(0, 1\\right). \n",
    "$$\n",
    "    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41053ef6",
   "metadata": {},
   "source": [
    "\n",
    "下面是一个模拟案例. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387646f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Z_fun = function(n, distribution){\n",
    "  if (distribution == \"normal\"){\n",
    "      z = sqrt(n) * mean(rnorm(n))\n",
    "\t} else if (distribution == \"chisq2\") {\n",
    "      df = 2; \n",
    "      x = rchisq(n,2)\n",
    "      z = sqrt(n) * ( mean(x) - df ) / sqrt(2*df)\n",
    "      }\n",
    "  return (z)\n",
    "}\n",
    "CLT_plot = function(n, distribution){\n",
    "  Rep = 10000\n",
    "  ZZ = rep(0, Rep)\n",
    "  for (i in 1:Rep) {ZZ[i] = Z_fun(n, distribution)}\n",
    "\n",
    "  xbase = seq(-4.0, 4.0, length.out = 100)\n",
    "  hist( ZZ, breaks = 100, freq = FALSE, \n",
    "    xlim = c( min(xbase), max(xbase) ),\n",
    "    main = paste0(\"hist with sample size \", n) )\n",
    "  lines(x = xbase, y = dnorm(xbase), col = \"red\")\n",
    "  return (ZZ)\n",
    "}\n",
    "\n",
    "par(mfrow = c(3,1))\n",
    "phist = CLT_plot(2, \"chisq2\")\n",
    "phist = CLT_plot(10, \"chisq2\")\n",
    "phist = CLT_plot(100, \"chisq2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a8cf1",
   "metadata": {},
   "source": [
    "\n",
    "## 转化方法\n",
    "\n",
    "大数定律事关样本均值, 而中心极限定理则聚焦于缩小后 (除以 $\\sqrt{n}$ ) 或标准化以后 (除以样本标准差) 的样本均值. 但是, 大多数计量经济学的问题不只是样本均值而已. 比如, 最小二乘估计量\n",
    "\n",
    "$$\n",
    "\\widehat{\\beta}=\\left(\\frac{1}{n}\\sum_{i}x_{i}x_{i}'\\right)^{-1}\\frac{1}{n}\\sum_{i}x_{i}y_{i}\n",
    "$$\n",
    "\n",
    "涉及矩阵求逆和矩阵-向量乘法. 在此, 我们需要一些转化随机变量的工具. \n",
    "\n",
    "```{prf:theorem} 连续映射定理 Continuous mapping theorem 1\n",
    ":label: cmp1\n",
    "\n",
    "如果 $x_{n}\\stackrel{p}{\\to}a$, 并且 $f\\left(\\cdot\\right)$ 在 $a$ 处连续, 那么 $f\\left(x_{n}\\right)\\stackrel{p}{\\to}f\\left(a\\right)$. \n",
    "```\n",
    "\n",
    "```{prf:theorem} 连续映射定理 Continuous mapping theorem 2\n",
    ":label: cmp2\n",
    "\n",
    "如果 $x_{n}\\stackrel{p}{\\to}a$, 并且 $f\\left(\\cdot\\right)$ 在 $x$ 的支撑集上 *几乎处处* 连续, 那么 $f\\left(x_{n}\\right)\\stackrel{d}{\\to}f\\left(x\\right)$. \n",
    "```\n",
    "\n",
    "\n",
    "```{prf:theorem} Slutsky’s theorem\n",
    ":label: slutsky\n",
    "\n",
    "假设 $x_{n}\\stackrel{d}{\\to}x$, $y_{n}\\stackrel{p}{\\to}a$, 那么\n",
    "* $x_{n}+y_{n}\\stackrel{d}{\\to}x+a$;\n",
    "* $x_{n}y_{n}\\stackrel{d}{\\to}ax$;\n",
    "* 若 $a\\neq0$, 则 $x_{n}/y_{n}\\stackrel{d}{\\to}x/a$. \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "{prf:ref}`Slutsky’s theorem <slutsky>` 只是 {prf:ref}`Continuous mapping theorem 2 <cmp2>` 的特殊情况. 由于加法、乘法、除法是现实中最常用的运算, 故将单列为定理. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e70ddb",
   "metadata": {},
   "source": [
    "\n",
    "````{prf:theorem} Delta method\n",
    ":label: delta\n",
    "\n",
    "假设 $\\sqrt{n}\\left(\\widehat{\\theta}-\\theta_{0}\\right)\\stackrel{d}{\\to}N\\left(0, \\Omega\\right)$, 并且 $f\\left(\\cdot\\right)$ 在 $\\theta_{0}$ 处连续可微 (即 $\\frac{\\partial}{\\partial\\theta}f\\left(\\cdot\\right)$ 在 $\\theta_{0}$ 处连续) , 那么\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)\\stackrel{d}{\\to}N\\left(0, \\frac{\\partial f}{\\partial\\theta'}\\left(\\theta_{0}\\right)\\Omega\\left(\\frac{\\partial f}{\\partial\\theta}\\left(\\theta_{0}\\right)\\right)'\\right). \n",
    "$$\n",
    "\n",
    "```{prf:proof}\n",
    "在 $\\theta_{0}$ 处取泰勒展开式 $f\\left(\\widehat{\\theta}\\right)$, 得\n",
    "\n",
    "$$\n",
    "f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)=\\frac{\\partial f\\left(\\dot{\\theta}\\right)}{\\partial\\theta'}\\left(\\widehat{\\theta}-\\theta_{0}\\right), \n",
    "$$\n",
    "\n",
    "其中 $\\dot{\\theta}$ 位于 $\\widehat{\\theta}$ 与 $\\theta_{0}$ 之间的线段上. \n",
    "\n",
    "等式两边同时乘以 $\\sqrt{n}$, 得到\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)=\\frac{\\partial f\\left(\\dot{\\theta}\\right)}{\\partial\\theta'}\\sqrt{n}\\left(\\widehat{\\theta}-\\theta_{0}\\right). \n",
    "$$\n",
    "\n",
    "因为可以由 $\\widehat{\\theta}\\stackrel{p}{\\to}\\theta_{0}$ 推导出 $\\dot{\\theta}\\stackrel{p}{\\to}\\theta_{0}$, 并且 $\\frac{\\partial}{\\partial\\theta'}f\\left(\\cdot\\right)$ 在 $\\theta_{0}$ 处连续, 所以根据 {prf:ref}`Continuous mapping theorem 1 <cmp1>`, 有 $\\frac{\\partial}{\\partial\\theta'}f\\left(\\dot{\\theta}\\right)\\stackrel{p}{\\to}\\frac{\\partial f\\left(\\theta_{0}\\right)}{\\partial\\theta'}$. \n",
    "\n",
    "另一方面, 由于 $\\sqrt{n}\\left(\\widehat{\\theta}-\\theta_{0}\\right)\\stackrel{d}{\\to}N\\left(0, \\Omega\\right)$, 根据 {prf:ref}`Slutsky’s theorem <slutsky>`可得\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(f\\left(\\widehat{\\theta}\\right)-f\\left(\\theta_{0}\\right)\\right)\\stackrel{d}{\\to}\\frac{\\partial f\\left(\\theta_{0}\\right)}{\\partial\\theta'}N\\left(0, \\Omega\\right). \n",
    "$$\n",
    "\n",
    "证明完毕. \n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0b228",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 总结\n",
    "\n",
    "渐进理论是一个既广且深的课题. 在本章中, 我们只触及了一些表面知识. 我们将在下一章继续探讨如何将渐进理论应用于最小二乘法. \n",
    "\n",
    "\n",
    "```{admonition} 历史趣闻\n",
    "\n",
    "在20世纪80年代之前, 大多数计量经济学家都没有受过严谨的数学训练, 因此无法很好地掌握渐进理论. 在当时, 几位著名的年轻计量经济学家改变了这一局面, 他们拓展了渐进理论在计量经济学中的发展. 其中的佼佼者有 Halbert White (UCSD), Peter C. B.  Phillips (Yale), 以及 Peter Robinson (LSE). \n",
    "```\n",
    "\n",
    "\n",
    "```{admonition} 拓展阅读\n",
    "Halbert White (1950-2012) 写过一本非常易懂的教科书 (White, 2000, first edition 1984) 向计量经济学家介绍渐进理论. 时至今日, 这本书在经济学研究者和研究生中仍然很受欢迎. 另外, Davidson (1994) 是一本更详细、自成一体的专著. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776849b5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0f3c2ff56be48af7298a14c9a97ca5fd7aeab5c1ef3d3151d92452bace946e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
